# Prometheus Configuration for Multi-Cloud Monitoring

apiVersion: v1
kind: Namespace
metadata:
  name: monitoring
  labels:
    istio-injection: enabled

---
apiVersion: monitoring.coreos.com/v1
kind: Prometheus
metadata:
  name: prometheus-multi-cloud
  namespace: monitoring
spec:
  serviceAccountName: prometheus
  serviceMonitorSelector:
    matchLabels:
      team: platform
  ruleSelector:
    matchLabels:
      team: platform
  resources:
    requests:
      memory: 400Mi
      cpu: 100m
    limits:
      memory: 2Gi
      cpu: 1000m
  retention: 30d
  storage:
    volumeClaimTemplate:
      spec:
        storageClassName: fast-ssd
        accessModes: ["ReadWriteOnce"]
        resources:
          requests:
            storage: 50Gi
  additionalScrapeConfigs:
    name: additional-scrape-configs
    key: prometheus-additional.yaml
  remoteWrite:
  - url: "http://prometheus-remote-storage.monitoring.svc.cluster.local:9201/write"
    writeRelabelConfigs:
    - sourceLabels: [__name__]
      regex: "(.*)"
      targetLabel: cluster
      replacement: "${CLUSTER_NAME}"
  externalLabels:
    cluster: "${CLUSTER_NAME}"
    region: "${CLUSTER_REGION}"
    cloud_provider: "${CLOUD_PROVIDER}"

---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: prometheus
  namespace: monitoring

---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: prometheus
rules:
- apiGroups: [""]
  resources:
  - nodes
  - nodes/proxy
  - nodes/metrics
  - services
  - endpoints
  - pods
  verbs: ["get", "list", "watch"]
- apiGroups: ["extensions"]
  resources:
  - ingresses
  verbs: ["get", "list", "watch"]
- apiGroups: ["networking.k8s.io"]
  resources:
  - ingresses
  verbs: ["get", "list", "watch"]
- nonResourceURLs: ["/metrics"]
  verbs: ["get"]

---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: prometheus
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: prometheus
subjects:
- kind: ServiceAccount
  name: prometheus
  namespace: monitoring

---
apiVersion: v1
kind: Secret
metadata:
  name: additional-scrape-configs
  namespace: monitoring
stringData:
  prometheus-additional.yaml: |
    # Cross-cluster scraping configuration
    - job_name: 'aws-cluster-prometheus'
      kubernetes_sd_configs:
      - role: endpoints
        api_server: '${AWS_CLUSTER_API_SERVER}'
        bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
        tls_config:
          ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
          insecure_skip_verify: true
      relabel_configs:
      - source_labels: [__meta_kubernetes_service_name]
        action: keep
        regex: prometheus
      - source_labels: [__meta_kubernetes_endpoint_port_name]
        action: keep
        regex: http
      - source_labels: [__address__]
        target_label: __address__
        replacement: '${AWS_CLUSTER_PROMETHEUS_ENDPOINT}'
      - target_label: cluster
        replacement: aws-cluster
    
    - job_name: 'azure-cluster-prometheus'
      kubernetes_sd_configs:
      - role: endpoints
        api_server: '${AZURE_CLUSTER_API_SERVER}'
        bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
        tls_config:
          ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
          insecure_skip_verify: true
      relabel_configs:
      - source_labels: [__meta_kubernetes_service_name]
        action: keep
        regex: prometheus
      - source_labels: [__meta_kubernetes_endpoint_port_name]
        action: keep
        regex: http
      - source_labels: [__address__]
        target_label: __address__
        replacement: '${AZURE_CLUSTER_PROMETHEUS_ENDPOINT}'
      - target_label: cluster
        replacement: azure-cluster
    
    - job_name: 'gcp-cluster-prometheus'
      kubernetes_sd_configs:
      - role: endpoints
        api_server: '${GCP_CLUSTER_API_SERVER}'
        bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
        tls_config:
          ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
          insecure_skip_verify: true
      relabel_configs:
      - source_labels: [__meta_kubernetes_service_name]
        action: keep
        regex: prometheus
      - source_labels: [__meta_kubernetes_endpoint_port_name]
        action: keep
        regex: http
      - source_labels: [__address__]
        target_label: __address__
        replacement: '${GCP_CLUSTER_PROMETHEUS_ENDPOINT}'
      - target_label: cluster
        replacement: gcp-cluster
    
    # Istio metrics scraping
    - job_name: 'istio-mesh'
      kubernetes_sd_configs:
      - role: endpoints
        namespaces:
          names:
          - istio-system
          - trustram-system
      relabel_configs:
      - source_labels: [__meta_kubernetes_service_name, __meta_kubernetes_endpoint_port_name]
        action: keep
        regex: istio-telemetry;prometheus

---
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: istio-mesh
  namespace: monitoring
  labels:
    team: platform
spec:
  selector:
    matchLabels:
      app: istiod
  endpoints:
  - port: http-monitoring
    interval: 15s
    path: /stats/prometheus

---
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: istio-proxy
  namespace: monitoring
  labels:
    team: platform
spec:
  selector:
    matchLabels:
      istio-prometheus-ignore: ""
  endpoints:
  - port: http-envoy-prom
    interval: 15s
    path: /stats/prometheus
    relabelings:
    - sourceLabels: [__meta_kubernetes_pod_container_name]
      action: keep
      regex: istio-proxy

---
apiVersion: v1
kind: Service
metadata:
  name: prometheus
  namespace: monitoring
  labels:
    app: prometheus
spec:
  type: ClusterIP
  ports:
  - name: web
    port: 9090
    protocol: TCP
    targetPort: web
  selector:
    app.kubernetes.io/name: prometheus

---
# Prometheus Alerting Rules for Multi-Cloud
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: multi-cloud-alerts
  namespace: monitoring
  labels:
    team: platform
spec:
  groups:
  - name: multi-cloud.rules
    rules:
    - alert: ClusterDown
      expr: up{job=~".*-cluster-prometheus"} == 0
      for: 1m
      labels:
        severity: critical
      annotations:
        summary: "Cluster {{ $labels.cluster }} is down"
        description: "Cluster {{ $labels.cluster }} has been down for more than 1 minute."
    
    - alert: HighErrorRate
      expr: |
        (
          sum(rate(istio_requests_total{response_code!~"2.."}[5m])) by (cluster, destination_service_name)
          /
          sum(rate(istio_requests_total[5m])) by (cluster, destination_service_name)
        ) > 0.05
      for: 2m
      labels:
        severity: warning
      annotations:
        summary: "High error rate detected"
        description: "Service {{ $labels.destination_service_name }} in cluster {{ $labels.cluster }} has error rate above 5%"
    
    - alert: HighLatency
      expr: |
        histogram_quantile(0.99,
          sum(rate(istio_request_duration_milliseconds_bucket[5m])) by (cluster, destination_service_name, le)
        ) > 1000
      for: 2m
      labels:
        severity: warning
      annotations:
        summary: "High latency detected"
        description: "Service {{ $labels.destination_service_name }} in cluster {{ $labels.cluster }} has 99th percentile latency above 1000ms"
    
    - alert: CrossClusterConnectivityLoss
      expr: |
        sum(rate(istio_requests_total{source_cluster!="unknown",destination_cluster!="unknown",source_cluster!=destination_cluster}[5m])) by (source_cluster, destination_cluster) == 0
      for: 5m
      labels:
        severity: critical
      annotations:
        summary: "Cross-cluster connectivity lost"
        description: "No traffic detected between {{ $labels.source_cluster }} and {{ $labels.destination_cluster }} for 5 minutes"
    
    - alert: PodMemoryUsageHigh
      expr: |
        (
          sum(container_memory_working_set_bytes{name!=""}) by (cluster, pod, namespace)
          /
          sum(container_spec_memory_limit_bytes > 0) by (cluster, pod, namespace)
        ) > 0.9
      for: 2m
      labels:
        severity: warning
      annotations:
        summary: "Pod memory usage is high"
        description: "Pod {{ $labels.pod }} in namespace {{ $labels.namespace }} in cluster {{ $labels.cluster }} is using more than 90% of its memory limit."
    
    - alert: NodeMemoryUsageHigh
      expr: |
        (
          1 - (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes)
        ) > 0.9
      for: 2m
      labels:
        severity: warning
      annotations:
        summary: "Node memory usage is high"
        description: "Node {{ $labels.instance }} in cluster {{ $labels.cluster }} is using more than 90% of its memory."

---
# AlertManager Configuration
apiVersion: monitoring.coreos.com/v1
kind: Alertmanager
metadata:
  name: main
  namespace: monitoring
spec:
  replicas: 3
  serviceAccountName: alertmanager
  configSecret: alertmanager-main
  storage:
    volumeClaimTemplate:
      spec:
        storageClassName: fast-ssd
        accessModes: ["ReadWriteOnce"]
        resources:
          requests:
            storage: 10Gi