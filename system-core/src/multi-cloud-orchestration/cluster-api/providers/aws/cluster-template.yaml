# AWS Cluster Template for Multi-Cloud Orchestration
# This defines the complete cluster configuration for AWS
apiVersion: cluster.x-k8s.io/v1beta1
kind: Cluster
metadata:
  name: trustram-aws-cluster
  namespace: default
  labels:
    cluster.x-k8s.io/cluster-name: trustram-aws-cluster
    environment: production
    cloud-provider: aws
    trustram-version: v4.4
spec:
  clusterNetwork:
    pods:
      cidrBlocks:
      - 192.168.0.0/16
    services:
      cidrBlocks:
      - 10.96.0.0/12
    serviceDomain: cluster.local
  
  # Infrastructure Reference
  infrastructureRef:
    apiVersion: infrastructure.cluster.x-k8s.io/v1beta2
    kind: AWSCluster
    name: trustram-aws-cluster
  
  # Control Plane Configuration
  controlPlaneRef:
    apiVersion: controlplane.cluster.x-k8s.io/v1beta1
    kind: KubeadmControlPlane
    name: trustram-aws-control-plane

---
# AWS Infrastructure Cluster
apiVersion: infrastructure.cluster.x-k8s.io/v1beta2
kind: AWSCluster
metadata:
  name: trustram-aws-cluster
  namespace: default
spec:
  # AWS Region
  region: us-west-2
  
  # VPC Configuration
  network:
    vpc:
      cidrBlock: "10.0.0.0/16"
      enableDnsHostnames: true
      enableDnsSupport: true
      tags:
        Name: "trustram-aws-vpc"
        Environment: "production"
        Project: "multi-cloud-orchestration"
    
    # Subnet Configuration for High Availability
    subnets:
    - cidrBlock: "10.0.1.0/24"
      availabilityZone: "us-west-2a"
      isPublic: true
      tags:
        Name: "trustram-public-1"
        kubernetes.io/role/elb: "1"
    - cidrBlock: "10.0.2.0/24"
      availabilityZone: "us-west-2b"
      isPublic: true
      tags:
        Name: "trustram-public-2"
        kubernetes.io/role/elb: "1"
    - cidrBlock: "10.0.3.0/24"
      availabilityZone: "us-west-2c"
      isPublic: true
      tags:
        Name: "trustram-public-3"
        kubernetes.io/role/elb: "1"
    - cidrBlock: "10.0.11.0/24"
      availabilityZone: "us-west-2a"
      isPublic: false
      tags:
        Name: "trustram-private-1"
        kubernetes.io/role/internal-elb: "1"
    - cidrBlock: "10.0.12.0/24"
      availabilityZone: "us-west-2b"
      isPublic: false
      tags:
        Name: "trustram-private-2"
        kubernetes.io/role/internal-elb: "1"
    - cidrBlock: "10.0.13.0/24"
      availabilityZone: "us-west-2c"
      isPublic: false
      tags:
        Name: "trustram-private-3"
        kubernetes.io/role/internal-elb: "1"
  
  # Control Plane Load Balancer
  controlPlaneLoadBalancer:
    scheme: internet-facing
    crossZoneLoadBalancing: true
    subnets:
    - "trustram-public-1"
    - "trustram-public-2"
    - "trustram-public-3"
  
  # IAM Configuration
  identityRef:
    kind: AWSClusterRoleIdentity
    name: default
  
  # S3 Bucket for Cluster State
  s3Bucket:
    name: "trustram-aws-cluster-state"
    region: "us-west-2"
  
  # Additional Tags for Resource Management
  additionalTags:
    "sigs.k8s.io/cluster-api-provider-aws/cluster/trustram-aws-cluster": "owned"
    "kubernetes.io/cluster/trustram-aws-cluster": "owned"
    "trustram.io/environment": "production"
    "trustram.io/version": "v4.4"
    "trustram.io/multi-cloud": "true"

---
# Control Plane Configuration
apiVersion: controlplane.cluster.x-k8s.io/v1beta1
kind: KubeadmControlPlane
metadata:
  name: trustram-aws-control-plane
  namespace: default
spec:
  # Control Plane Replica Configuration
  replicas: 3
  version: v1.28.2
  
  # Machine Template Reference
  machineTemplate:
    infrastructureRef:
      apiVersion: infrastructure.cluster.x-k8s.io/v1beta2
      kind: AWSMachineTemplate
      name: aws-control-plane-machine-template
  
  # Kubeadm Configuration
  kubeadmConfigSpec:
    # Cluster Configuration
    clusterConfiguration:
      apiServer:
        extraArgs:
          cloud-provider: aws
          enable-admission-plugins: NodeRestriction,MutatingAdmissionWebhook,ValidatingAdmissionWebhook
          audit-log-maxage: "30"
          audit-log-maxbackup: "3"
          audit-log-maxsize: "100"
          audit-log-path: /var/log/audit.log
        timeoutForControlPlane: 20m
      controllerManager:
        extraArgs:
          cloud-provider: aws
          enable-hostpath-provisioner: "true"
      etcd:
        local:
          dataDir: /var/lib/etcd
          extraArgs:
            listen-metrics-urls: http://0.0.0.0:2381
      kubernetesVersion: v1.28.2
      controlPlaneEndpoint: ""
      networking:
        podSubnet: 192.168.0.0/16
        serviceSubnet: 10.96.0.0/12
    
    # Init Configuration
    initConfiguration:
      nodeRegistration:
        criSocket: unix:///var/run/containerd/containerd.sock
        kubeletExtraArgs:
          cloud-provider: aws
          provider-id: aws:///'$(curl -s http://169.254.169.254/latest/meta-data/placement/availability-zone)'/'$(curl -s http://169.254.169.254/latest/meta-data/instance-id)'
    
    # Join Configuration
    joinConfiguration:
      nodeRegistration:
        criSocket: unix:///var/run/containerd/containerd.sock
        kubeletExtraArgs:
          cloud-provider: aws
          provider-id: aws:///'$(curl -s http://169.254.169.254/latest/meta-data/placement/availability-zone)'/'$(curl -s http://169.254.169.254/latest/meta-data/instance-id)'
    
    # Pre and Post Kubeadm Commands
    preKubeadmCommands:
    - hostnamectl set-hostname "$(curl -s http://169.254.169.254/latest/meta-data/local-hostname)"
    - echo "127.0.0.1 $(curl -s http://169.254.169.254/latest/meta-data/local-hostname)" >> /etc/hosts
    
    postKubeadmCommands:
    # Install AWS Cloud Controller Manager
    - kubectl apply -f https://raw.githubusercontent.com/kubernetes/cloud-provider-aws/master/manifests/rbac.yaml
    - kubectl apply -f https://raw.githubusercontent.com/kubernetes/cloud-provider-aws/master/manifests/aws-cloud-controller-manager-daemonset.yaml
    
    # Install AWS EBS CSI Driver
    - kubectl apply -k "github.com/kubernetes-sigs/aws-ebs-csi-driver/deploy/kubernetes/overlays/stable/?ref=release-1.24"
    
    # Install Calico CNI
    - kubectl apply -f https://raw.githubusercontent.com/projectcalico/calico/v3.26.1/manifests/calico.yaml
    
    # Files for AWS integration
    files:
    - path: /etc/kubernetes/aws.yaml
      content: |
        apiVersion: v1
        kind: ConfigMap
        metadata:
          name: aws-auth
          namespace: kube-system
        data:
          mapRoles: |
            - rolearn: arn:aws:iam::ACCOUNT-ID:role/NodeInstanceRole
              username: system:node:{{EC2PrivateDNSName}}
              groups:
                - system:bootstrappers
                - system:nodes
      permissions: "0644"

---
# Worker Node Machine Pool
apiVersion: cluster.x-k8s.io/v1beta1
kind: MachinePool
metadata:
  name: trustram-aws-worker-pool
  namespace: default
  labels:
    cluster.x-k8s.io/cluster-name: trustram-aws-cluster
spec:
  clusterName: trustram-aws-cluster
  replicas: 3
  
  template:
    spec:
      clusterName: trustram-aws-cluster
      version: v1.28.2
      
      # Infrastructure Template
      infrastructureRef:
        apiVersion: infrastructure.cluster.x-k8s.io/v1beta2
        kind: AWSMachinePool
        name: trustram-aws-worker-machine-pool
      
      # Bootstrap Configuration
      bootstrap:
        configRef:
          apiVersion: bootstrap.cluster.x-k8s.io/v1beta1
          kind: KubeadmConfig
          name: trustram-aws-worker-bootstrap

---
# AWS Machine Pool for Workers
apiVersion: infrastructure.cluster.x-k8s.io/v1beta2
kind: AWSMachinePool
metadata:
  name: trustram-aws-worker-machine-pool
  namespace: default
spec:
  # Minimum and Maximum Sizes for Auto-scaling
  minSize: 3
  maxSize: 10
  
  # AWS Launch Template
  awsLaunchTemplate:
    instanceType: m5.large
    ami:
      id: "ami-0abcdef1234567890"  # Ubuntu 22.04 LTS
    
    # Root Volume Configuration
    rootVolume:
      size: 100
      type: gp3
      iops: 3000
      throughput: 125
      encrypted: true
    
    # Security Groups
    securityGroupSelector:
      matchLabels:
        "sigs.k8s.io/cluster-api-provider-aws/cluster/trustram-aws-cluster": "owned"
        "sigs.k8s.io/cluster-api-provider-aws/role": "node"
    
    # SSH Key
    sshKeyName: "trustram-keypair"
    
    # Instance Metadata Options
    instanceMetadataOptions:
      httpEndpoint: "enabled"
      httpPutResponseHopLimit: 2
      httpTokens: "required"
    
    # Spot Instance Configuration for Cost Optimization
    spotMarketOptions:
      maxPrice: "0.10"
  
  # Subnet Selection
  subnets:
  - id: "trustram-private-1"
  - id: "trustram-private-2"
  - id: "trustram-private-3"
  
  # Additional Tags
  additionalTags:
    "trustram.io/nodepool": "worker"
    "trustram.io/environment": "production"
    "trustram.io/cost-optimization": "spot-instances"

---
# Worker Bootstrap Configuration
apiVersion: bootstrap.cluster.x-k8s.io/v1beta1
kind: KubeadmConfig
metadata:
  name: trustram-aws-worker-bootstrap
  namespace: default
spec:
  joinConfiguration:
    nodeRegistration:
      criSocket: unix:///var/run/containerd/containerd.sock
      kubeletExtraArgs:
        cloud-provider: aws
        provider-id: aws:///'$(curl -s http://169.254.169.254/latest/meta-data/placement/availability-zone)'/'$(curl -s http://169.254.169.254/latest/meta-data/instance-id)'
  
  preKubeadmCommands:
  - hostnamectl set-hostname "$(curl -s http://169.254.169.254/latest/meta-data/local-hostname)"
  - echo "127.0.0.1 $(curl -s http://169.254.169.254/latest/meta-data/local-hostname)" >> /etc/hosts
