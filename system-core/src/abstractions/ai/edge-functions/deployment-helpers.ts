/**
 * AI Service Deployment Helpers for Supabase Edge Functions
 * Provides utilities for deploying and integrating AI services with Supabase
 */

import { AIConfig } from '../ai.interface';
import { UnifiedAIService } from '../UnifiedAIService';

export interface EdgeFunctionAITemplate {
  functionName: string;
  description: string;
  code: string;
  dependencies?: string[];
  environment?: Record<string, string>;
}

export interface DeploymentOptions {
  functionName: string;
  aiConfig: AIConfig;
  enableCors?: boolean;
  enableAuth?: boolean;
  enableRateLimit?: boolean;
  rateLimitRpm?: number;
  enableLogging?: boolean;
  enableMetrics?: boolean;
  customHeaders?: Record<string, string>;
}

export class AIEdgeFunctionDeploymentHelper {
  /**
   * Generate Supabase Edge Function code for AI service
   */
  static generateEdgeFunctionCode(options: DeploymentOptions): EdgeFunctionAITemplate {
    const {
      functionName,
      aiConfig,
      enableCors = true,
      enableAuth = false,
      enableRateLimit = false,
      rateLimitRpm = 60,
      enableLogging = true,
      enableMetrics = true,
      customHeaders = {}
    } = options;

    const corsHeaders = enableCors ? `
    const corsHeaders = {
      'Access-Control-Allow-Origin': '*',
      'Access-Control-Allow-Headers': 'authorization, x-client-info, apikey, content-type',
      'Access-Control-Allow-Methods': 'POST, GET, OPTIONS, PUT, DELETE, PATCH',
      'Access-Control-Max-Age': '86400',
      'Access-Control-Allow-Credentials': 'false',
      ...customHeaders
    };` : '';

    const authCheck = enableAuth ? `
    // Check authentication
    const authHeader = req.headers.get('authorization');
    if (!authHeader || !authHeader.startsWith('Bearer ')) {
      return new Response(
        JSON.stringify({ error: { code: 'UNAUTHORIZED', message: 'Missing or invalid authorization header' } }),
        { status: 401, headers: { ...corsHeaders, 'Content-Type': 'application/json' } }
      );
    }

    const token = authHeader.replace('Bearer ', '');
    // Validate token with Supabase auth if needed
    // const { data: { user }, error } = await supabase.auth.getUser(token);
    // if (error || !user) {
    //   return new Response(
    //     JSON.stringify({ error: { code: 'UNAUTHORIZED', message: 'Invalid token' } }),
    //     { status: 401, headers: { ...corsHeaders, 'Content-Type': 'application/json' } }
    //   );
    // }` : '';

    const rateLimitCheck = enableRateLimit ? `
    // Rate limiting (simple in-memory store - consider Redis for production)
    const clientIp = req.headers.get('x-forwarded-for') || req.headers.get('x-real-ip') || 'unknown';
    const rateLimitKey = \`ai_\${clientIp}\`;
    
    // This is a simplified rate limit - implement proper rate limiting with external store
    // const rateLimitCount = await rateLimitStore.increment(rateLimitKey, ${rateLimitRpm}, 60);
    // if (rateLimitCount > ${rateLimitRpm}) {
    //   return new Response(
    //     JSON.stringify({ error: { code: 'RATE_LIMIT_EXCEEDED', message: 'Too many requests' } }),
    //     { status: 429, headers: { ...corsHeaders, 'Content-Type': 'application/json' } }
    //   );
    // }` : '';

    const loggingCode = enableLogging ? `
    const logRequest = (level: string, message: string, metadata?: any) => {
      console.log(JSON.stringify({
        timestamp: new Date().toISOString(),
        level,
        function: '${functionName}',
        message,
        metadata
      }));
    };` : 'const logRequest = () => {};';

    const metricsCode = enableMetrics ? `
    const recordMetric = async (metric: string, value: number, tags?: Record<string, string>) => {
      // Implement metrics recording (e.g., to analytics service)
      logRequest('info', 'Metric recorded', { metric, value, tags });
    };` : 'const recordMetric = async () => {};';

    const aiConfigString = JSON.stringify(aiConfig, null, 2);

    const code = `/**
 * ${functionName} - AI Service Edge Function
 * Auto-generated by AI Service Deployment Helper
 */

import { UnifiedAIService } from '../../../src/abstractions/ai/index.ts';

// IMPORTANT: This edge function requires the AI abstraction layer to be available
// Make sure to deploy the AI service files to your Supabase project

Deno.serve(async (req) => {
  ${corsHeaders}

  ${loggingCode}

  ${metricsCode}

  // Handle CORS preflight
  if (req.method === 'OPTIONS') {
    return new Response(null, { status: 200, headers: corsHeaders });
  }

  const startTime = Date.now();

  try {
    ${authCheck}

    ${rateLimitCheck}

    // Initialize AI service
    const aiConfig = ${aiConfigString};
    
    // Override sensitive config from environment variables
    if (aiConfig.type === 'openai' && aiConfig.openai) {
      aiConfig.openai.apiKey = Deno.env.get('OPENAI_API_KEY') || aiConfig.openai.apiKey;
    }
    if (aiConfig.type === 'anthropic' && aiConfig.anthropic) {
      aiConfig.anthropic.apiKey = Deno.env.get('ANTHROPIC_API_KEY') || aiConfig.anthropic.apiKey;
    }
    if (aiConfig.type === 'local-llm' && aiConfig.localLLM) {
      aiConfig.localLLM.endpoint = Deno.env.get('LOCAL_LLM_ENDPOINT') || aiConfig.localLLM.endpoint;
      aiConfig.localLLM.apiKey = Deno.env.get('LOCAL_LLM_API_KEY') || aiConfig.localLLM.apiKey;
    }

    const aiService = new UnifiedAIService({
      enableCaching: true,
      enableMetrics: ${enableMetrics},
      retryAttempts: 2
    });

    await aiService.connect(aiConfig);

    // Parse request body
    const requestData = await req.json();
    const { action, ...params } = requestData;

    logRequest('info', 'Processing AI request', { action, hasParams: !!params });

    let result;
    const processingStartTime = Date.now();

    switch (action) {
      case 'generateText':
        result = await aiService.generateText(params.prompt, params.options);
        break;
      
      case 'chatCompletion':
        result = await aiService.chatCompletion(params.messages, params.options);
        break;
      
      case 'generateEmbedding':
        result = await aiService.generateEmbedding(params.text, params.options);
        break;
      
      case 'generateEmbeddings':
        result = await aiService.generateEmbeddings(params.texts, params.options);
        break;
      
      case 'analyzeImage':
        if (aiService.supportsFeature('vision')) {
          result = await aiService.analyzeImage(params.image, params.prompt, params.options);
        } else {
          throw new Error('Vision analysis not supported by current provider');
        }
        break;
      
      case 'transcribeAudio':
        if (aiService.supportsFeature('audioTranscription')) {
          result = await aiService.transcribeAudio(params.audio, params.options);
        } else {
          throw new Error('Audio transcription not supported by current provider');
        }
        break;
      
      case 'getStats':
        result = await aiService.getStats();
        break;
      
      case 'getCapabilities':
        result = aiService.getCapabilities();
        break;
      
      default:
        throw new Error(\`Unsupported action: \${action}\`);
    }

    const processingTime = Date.now() - processingStartTime;
    const totalTime = Date.now() - startTime;

    await recordMetric('ai_request_duration', totalTime, { action, provider: aiConfig.type });
    await recordMetric('ai_processing_duration', processingTime, { action, provider: aiConfig.type });

    logRequest('info', 'AI request completed', { 
      action, 
      processingTime, 
      totalTime,
      success: true 
    });

    // Cleanup
    await aiService.disconnect();

    return new Response(
      JSON.stringify({ 
        data: result,
        metadata: {
          processingTime,
          totalTime,
          provider: aiConfig.type,
          action
        }
      }),
      { 
        headers: { 
          ...corsHeaders, 
          'Content-Type': 'application/json' 
        } 
      }
    );

  } catch (error) {
    const totalTime = Date.now() - startTime;
    
    await recordMetric('ai_request_error', 1, { 
      error: error instanceof Error ? error.name : 'UnknownError' 
    });

    logRequest('error', 'AI request failed', { 
      error: error instanceof Error ? error.message : 'Unknown error',
      totalTime
    });

    const errorResponse = {
      error: {
        code: error instanceof Error ? error.name : 'UNKNOWN_ERROR',
        message: error instanceof Error ? error.message : 'An unknown error occurred'
      },
      metadata: {
        totalTime,
        timestamp: new Date().toISOString()
      }
    };

    return new Response(
      JSON.stringify(errorResponse),
      { 
        status: 500, 
        headers: { 
          ...corsHeaders, 
          'Content-Type': 'application/json' 
        } 
      }
    );
  }
});`;

    return {
      functionName,
      description: `AI Service Edge Function for ${aiConfig.type} provider`,
      code,
      dependencies: ['@supabase/supabase-js'],
      environment: this.getEnvironmentVariables(aiConfig)
    };
  }

  /**
   * Generate environment variables for the edge function
   */
  private static getEnvironmentVariables(config: AIConfig): Record<string, string> {
    const env: Record<string, string> = {};

    switch (config.type) {
      case 'openai':
        env.OPENAI_API_KEY = 'your-openai-api-key';
        if (config.openai?.baseURL) {
          env.OPENAI_BASE_URL = config.openai.baseURL;
        }
        break;
      
      case 'anthropic':
        env.ANTHROPIC_API_KEY = 'your-anthropic-api-key';
        if (config.anthropic?.baseURL) {
          env.ANTHROPIC_BASE_URL = config.anthropic.baseURL;
        }
        break;
      
      case 'local-llm':
        env.LOCAL_LLM_ENDPOINT = config.localLLM?.endpoint || 'your-local-llm-endpoint';
        if (config.localLLM?.apiKey) {
          env.LOCAL_LLM_API_KEY = 'your-local-llm-api-key';
        }
        break;
      
      case 'azure':
        env.AZURE_OPENAI_API_KEY = 'your-azure-api-key';
        env.AZURE_OPENAI_ENDPOINT = config.azure?.endpoint || 'your-azure-endpoint';
        break;
    }

    return env;
  }

  /**
   * Generate a complete deployment package
   */
  static generateDeploymentPackage(options: DeploymentOptions): {
    edgeFunction: EdgeFunctionAITemplate;
    deploymentScript: string;
    readme: string;
  } {
    const edgeFunction = this.generateEdgeFunctionCode(options);

    const deploymentScript = `#!/bin/bash
# Deployment script for ${options.functionName}

echo "Deploying AI Edge Function: ${options.functionName}"

# Create the function directory
mkdir -p supabase/functions/${options.functionName}

# Copy the function code
cp index.ts supabase/functions/${options.functionName}/

# Deploy the function
supabase functions deploy ${options.functionName}

echo "Deployment completed!"
echo "Function URL: https://your-project.supabase.co/functions/v1/${options.functionName}"
`;

    const readme = `# ${options.functionName} - AI Edge Function

This edge function provides AI services using the ${options.aiConfig.type} provider.

## Setup

1. Install Supabase CLI:
   \`\`\`bash
   npm install -g supabase
   \`\`\`

2. Login to Supabase:
   \`\`\`bash
   supabase login
   \`\`\`

3. Set environment variables:
   \`\`\`bash
${Object.entries(this.getEnvironmentVariables(options.aiConfig))
  .map(([key, value]) => `   supabase secrets set ${key}=${value}`)
  .join('\n')}
   \`\`\`

4. Deploy the function:
   \`\`\`bash
   chmod +x deploy.sh
   ./deploy.sh
   \`\`\`

## Usage

### Text Generation
\`\`\`javascript
const response = await fetch('https://your-project.supabase.co/functions/v1/${options.functionName}', {
  method: 'POST',
  headers: {
    'Content-Type': 'application/json',
    'Authorization': 'Bearer YOUR_ANON_KEY'
  },
  body: JSON.stringify({
    action: 'generateText',
    prompt: 'Hello, world!',
    options: {
      maxTokens: 100,
      temperature: 0.7
    }
  })
});

const result = await response.json();
console.log(result.data);
\`\`\`

### Chat Completion
\`\`\`javascript
const response = await fetch('https://your-project.supabase.co/functions/v1/${options.functionName}', {
  method: 'POST',
  headers: {
    'Content-Type': 'application/json',
    'Authorization': 'Bearer YOUR_ANON_KEY'
  },
  body: JSON.stringify({
    action: 'chatCompletion',
    messages: [
      { role: 'user', content: 'Hello!' }
    ],
    options: {
      maxTokens: 100
    }
  })
});

const result = await response.json();
console.log(result.data);
\`\`\`

### Generate Embeddings
\`\`\`javascript
const response = await fetch('https://your-project.supabase.co/functions/v1/${options.functionName}', {
  method: 'POST',
  headers: {
    'Content-Type': 'application/json',
    'Authorization': 'Bearer YOUR_ANON_KEY'
  },
  body: JSON.stringify({
    action: 'generateEmbedding',
    text: 'Sample text for embedding'
  })
});

const result = await response.json();
console.log(result.data);
\`\`\`

## Configuration

The function is configured for:
- Provider: ${options.aiConfig.type}
- CORS: ${options.enableCors ? 'Enabled' : 'Disabled'}
- Authentication: ${options.enableAuth ? 'Enabled' : 'Disabled'}
- Rate Limiting: ${options.enableRateLimit ? `Enabled (${options.rateLimitRpm} RPM)` : 'Disabled'}
- Logging: ${options.enableLogging ? 'Enabled' : 'Disabled'}
- Metrics: ${options.enableMetrics ? 'Enabled' : 'Disabled'}

## Monitoring

Check function logs:
\`\`\`bash
supabase functions logs ${options.functionName}
\`\`\`

## Troubleshooting

1. Check environment variables are set correctly
2. Verify API keys have proper permissions
3. Monitor function logs for errors
4. Check Supabase project quotas and limits
`;

    return {
      edgeFunction,
      deploymentScript,
      readme
    };
  }

  /**
   * Generate TypeScript client for the edge function
   */
  static generateTypeScriptClient(functionName: string, baseUrl: string): string {
    return `/**
 * TypeScript client for ${functionName} AI Edge Function
 */

export interface AIClientOptions {
  apiKey: string;
  baseUrl?: string;
}

export interface TextGenerationRequest {
  prompt: string;
  options?: {
    maxTokens?: number;
    temperature?: number;
    topP?: number;
    stop?: string[];
  };
}

export interface ChatCompletionRequest {
  messages: Array<{
    role: 'system' | 'user' | 'assistant';
    content: string;
  }>;
  options?: {
    maxTokens?: number;
    temperature?: number;
  };
}

export interface EmbeddingRequest {
  text: string;
  options?: {
    model?: string;
  };
}

export class AI${functionName.charAt(0).toUpperCase() + functionName.slice(1)}Client {
  private apiKey: string;
  private baseUrl: string;

  constructor(options: AIClientOptions) {
    this.apiKey = options.apiKey;
    this.baseUrl = options.baseUrl || '${baseUrl}';
  }

  private async makeRequest(action: string, params: any) {
    const response = await fetch(\`\${this.baseUrl}/functions/v1/${functionName}\`, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': \`Bearer \${this.apiKey}\`
      },
      body: JSON.stringify({ action, ...params })
    });

    if (!response.ok) {
      const error = await response.json();
      throw new Error(\`AI request failed: \${error.error?.message || 'Unknown error'}\`);
    }

    return response.json();
  }

  async generateText(request: TextGenerationRequest) {
    return this.makeRequest('generateText', request);
  }

  async chatCompletion(request: ChatCompletionRequest) {
    return this.makeRequest('chatCompletion', request);
  }

  async generateEmbedding(request: EmbeddingRequest) {
    return this.makeRequest('generateEmbedding', request);
  }

  async generateEmbeddings(texts: string[], options?: { model?: string }) {
    return this.makeRequest('generateEmbeddings', { texts, options });
  }

  async getStats() {
    return this.makeRequest('getStats', {});
  }

  async getCapabilities() {
    return this.makeRequest('getCapabilities', {});
  }
}
`;
  }
}

/**
 * Quick deployment helper functions
 */
export const AIDeploymentHelpers = {
  /**
   * Generate a basic AI edge function with OpenAI
   */
  generateOpenAIFunction: (functionName: string, apiKey: string) =>
    AIEdgeFunctionDeploymentHelper.generateDeploymentPackage({
      functionName,
      aiConfig: {
        type: 'openai',
        openai: { apiKey },
        caching: { enabled: true },
        monitoring: { enabled: true }
      },
      enableCors: true,
      enableLogging: true,
      enableMetrics: true
    }),

  /**
   * Generate a local LLM edge function
   */
  generateLocalLLMFunction: (functionName: string, endpoint: string) =>
    AIEdgeFunctionDeploymentHelper.generateDeploymentPackage({
      functionName,
      aiConfig: {
        type: 'local-llm',
        localLLM: { endpoint, gpu: true },
        caching: { enabled: true },
        monitoring: { enabled: true }
      },
      enableCors: true,
      enableLogging: true,
      enableMetrics: true
    }),

  /**
   * Generate a secure AI function with authentication
   */
  generateSecureAIFunction: (functionName: string, config: AIConfig) =>
    AIEdgeFunctionDeploymentHelper.generateDeploymentPackage({
      functionName,
      aiConfig: config,
      enableCors: true,
      enableAuth: true,
      enableRateLimit: true,
      rateLimitRpm: 30,
      enableLogging: true,
      enableMetrics: true
    })
};
